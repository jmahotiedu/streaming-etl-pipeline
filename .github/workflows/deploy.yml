name: Deploy

on:
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - "src/**"
      - "dags/**"
      - "Dockerfile.*"

env:
  AWS_REGION: us-east-1
  ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com

jobs:
  preflight:
    runs-on: ubuntu-latest
    outputs:
      has_aws_credentials: ${{ steps.check.outputs.has_aws_credentials }}
      has_mwaa_bucket: ${{ steps.check.outputs.has_mwaa_bucket }}
    steps:
      - id: check
        shell: bash
        env:
          AWS_DEPLOY_ROLE_ARN: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          MWAA_DAGS_BUCKET: ${{ secrets.MWAA_DAGS_BUCKET }}
        run: |
          has_aws_credentials=true
          has_mwaa_bucket=true

          if [[ -z "${AWS_DEPLOY_ROLE_ARN}" || -z "${AWS_ACCOUNT_ID}" ]]; then
            has_aws_credentials=false
            echo "::warning::Skipping image build/push: missing AWS_DEPLOY_ROLE_ARN and/or AWS_ACCOUNT_ID secret."
          fi

          if [[ -z "${MWAA_DAGS_BUCKET}" ]]; then
            has_mwaa_bucket=false
            echo "::warning::Skipping DAG upload: missing MWAA_DAGS_BUCKET secret."
          fi

          echo "has_aws_credentials=${has_aws_credentials}" >> "${GITHUB_OUTPUT}"
          echo "has_mwaa_bucket=${has_mwaa_bucket}" >> "${GITHUB_OUTPUT}"

  build-and-push:
    needs: preflight
    if: ${{ needs.preflight.outputs.has_aws_credentials == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push producer image
        run: |
          docker build -f Dockerfile.producer -t ${{ env.ECR_REGISTRY }}/streaming-etl-producer:${{ github.sha }} .
          docker push ${{ env.ECR_REGISTRY }}/streaming-etl-producer:${{ github.sha }}
          docker tag ${{ env.ECR_REGISTRY }}/streaming-etl-producer:${{ github.sha }} ${{ env.ECR_REGISTRY }}/streaming-etl-producer:latest
          docker push ${{ env.ECR_REGISTRY }}/streaming-etl-producer:latest

      - name: Build and push spark image
        run: |
          docker build -f Dockerfile.spark -t ${{ env.ECR_REGISTRY }}/streaming-etl-spark:${{ github.sha }} .
          docker push ${{ env.ECR_REGISTRY }}/streaming-etl-spark:${{ github.sha }}
          docker tag ${{ env.ECR_REGISTRY }}/streaming-etl-spark:${{ github.sha }} ${{ env.ECR_REGISTRY }}/streaming-etl-spark:latest
          docker push ${{ env.ECR_REGISTRY }}/streaming-etl-spark:latest

  upload-dags:
    if: ${{ needs.preflight.outputs.has_aws_credentials == 'true' && needs.preflight.outputs.has_mwaa_bucket == 'true' }}
    runs-on: ubuntu-latest
    needs: [preflight, build-and-push]
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Upload DAGs to S3
        run: |
          aws s3 sync dags/ s3://${{ secrets.MWAA_DAGS_BUCKET }}/dags/ --delete
